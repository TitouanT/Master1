Le pouvoir.
C'est le mot qui vient à l'esprit.
Nous sommes les nouveaux technologues.
Nous avons beaucoup de données, donc nous avons beaucoup de pouvoir.
Quelle quantité de pouvoir avons-nous ?
Une scène du film "Apocalypse Now" -- un grand film.
Nous devons amener notre héros, le capitaine Willard, à l'embouchure de la rivière Nung,
pour qu'il puisse poursuivre le colonel Kurtz.
Pour cela, nous allons le transporter en hélico et le déposer.
Dans cette scène :
le ciel est rempli de cette flotte d'hélicoptères qui le transportent.
Il y a cette musique bruyante et palpitante en fond,
cette musique effrénée.
♫ Dum da ta da dum ♫
♫ Dum da ta da dum ♫
♫ Da ta da da ♫
C'est un grand pouvoir.
C'est le genre de pouvoir que je ressens dans cette pièce.
C'est le genre de pouvoir que nous avons
grâce à toutes les données que nous possédons.
Prenons un exemple.
Que pouvons-nous faire
avec les données d'une seule personne ?
Que pouvons-nous faire
avec les données de ce type ?
Je peux regarder vos registres financiers.
Je peux vous dire si vous payez vos factures à temps.
Je sais alors si je peux vous faire un prêt.
Je peux regarder votre dossier médical, je peux voir si votre cœur fonctionne bien --
voir si je peux vous proposer une assurance.
Je peux regarder où vous cliquez sur Internet.
Quand vous visitez mon site, je sais déjà ce que vous allez faire,
parce que je vous ai vu visiter des millions de sites auparavant.
Je suis désolé de vous dire,
vous êtes comme un joueur de poker, vous avez des manies.
Je peux dire grâce à l'analyse de données ce que vous allez faire
avant même que vous ne le fassiez.
Je sais ce que vous aimez. Je sais qui vous êtes.
Et cela avant même que je regarde votre courrier
ou votre téléphone.
Ce sont le genre de choses que nous pouvons faire
avec les données que nous avons.
Mais je ne suis pas là pour parler de ce que nous pouvons faire.
Je suis ici pour parler de ce que nous devrions faire.
Quelle est la bonne chose à faire ?
Je vois des regards perplexes
comme « Pourquoi nous demandez-vous quelle est la bonne chose à faire ?
On ne fait que construire ce truc. Quelqu'un d'autre l'utilise. »
Très bien.
Mais ça me ramène en arrière.
Je pense à la deuxième guerre mondiale --
certains de nos grands technologues de l'époque,
certains de nos grands physiciens,
qui étudiaient la fission et la fusion nucléaires --
juste des trucs nucléaires.
Nous rassemblons ces physiciens ensemble à Los Alamos
pour voir ce qu'ils vont construire.
Nous voulons que les personnes qui construisent la technologie
pensent à ce que nous devrions faire avec la technologie.
Que devrions-nous donc faire avec les données de ce type ?
Devrions-nous les collecter, les rassembler,
pour optimiser son surf sur Internet ?
Pour faire de l'argent ?
Pour que nous puissions nous protéger
s'il a de mauvaises intentions ?
Ou devrions-nous respecter son intimité,
protéger sa dignité et le laisser tranquille ?
Que fait-on ?
Comment décidons-nous ?
Je sais : la participation citoyenne. Faisons du crowdsourcing.
Pour donner de l'entrain aux gens,
commençons par une question facile --
une chose sur laquelle tout le monde ici a une idée, j'en suis sûr :
iPhone contre Android.
Levez vos mains pour l'iPhone.
Uh huh.
Android.
Je pensais qu'une assemblée de gens intelligents
ne succomberait pas si facilement aux jolis téléphones.
(Rires)
Question suivante.
Un peu plus difficile.
Devrions-nous collecter toutes les données de ce type
pour optimiser son surf sur Internet
et pour nous protéger au cas où il aurait de mauvaises intentions ?
Ou devrions-nous le laisser tranquille ?
Rassembler ses données.
Le laisser tranquille.
Vous êtes hors de danger, c'est bon.
(Rires)
Bien, dernière question --
plus difficile --
quand on essaye d'estimer
ce que nous devrions faire dans cette situation,
devrions-nous utiliser le système moral déontologique de Kant,
ou bien le système moral conséquentialiste de Mill ?
Kant.
Mill.
Pas autant de voix.
(Rires)
Oui, c'est un résultat terrifiant.
Terrifiant, parce que nous avons des opinions plus fortes
sur nos appareils téléphones
que sur les systèmes moraux
que nous devrions utiliser pour orienter nos décisions.
Que faire de tout le pouvoir que nous avons
si nous n'avons pas de système moral ?
Nous en savons davantage sur les systèmes d'exploitation de nos téléphones,
alors que ce dont nous avons vraiment besoin est d'un système d'exploitation moral.
Qu'est-ce qu'un système d'exploitation moral ?
Nous connaissons tous le bien et le mal.
Vous vous sentez bien quand vous faites quelque chose de juste,
vous vous sentez mal quand vous faites le mal.
Nos parents nous l'apprennent : louer le bien, réprimander le mal.
Mais comment savoir ce qui est bien et ce qui est mal ?
De jour en jour, nous utilisons des techniques.
Peut-être que nous suivons simplement notre instinct.
Peut-être que nous procédons à un vote -- le crowdsourcing.
Ou peut-être que nous nous déchargeons --
nous demandons le service juridique, voir ce qu'ils en pensent.
En d'autres mots, c'est plutôt aléatoire,
c'est plutôt ad hoc,
la façon dont nous décidons de ce que nous devrions faire.
Peut-être que si nous voulons adopter une position plus sûre,
ce que nous voulons vraiment est un système moral qui nous aidera à nous y orienter,
qui nous dira qu'est-ce qui est bien et qu'est-ce qui est mal dès le départ,
et comment savoir quoi faire dans une situation donnée.
Prenons donc un cadre moral.
Nous vivons dans un monde de chiffres.
Comment pouvons-nous utiliser les chiffres
comme base d'un système moral ?
Je connais quelqu'un qui a fait exactement cela,
quelqu'un de brillant --
il est mort il y a 2 500 ans.
Platon, c'est exact.
Vous vous rappelez de lui -- le vieux philosophe ?
Vous dormiez pendant les cours.
Platon partageait beaucoup de nos préoccupations.
Il se préoccupait du bien et du mal.
Il voulait savoir ce qui était juste.
Mais il s'inquiétait que tout ce que nous semblons faire,
c'est échanger des opinions sur le sujet.
Il me dit que quelque chose est juste. Elle me dit qu'autre chose est juste.
Les deux sont plutôt convaincants quand ils parlent.
Je fais des allers retours ; je n'avance pas.
Je ne veux pas d'opinions, je veux de la connaissance.
Je veux connaître la vérité sur la justice --
comme on connait les vérités mathématiques.
En maths, on connait les faits concrets.
Prenez un chiffre, n'importe lequel -- deux.
Mon chiffre préféré. J'adore ce chiffre.
Il y a des vérités sur le chiffre deux.
Si vous avez une chose en deux exemplaires,
vous en ajoutez deux, vous en obtenez quatre.
C'est vrai pour n'importe quelle chose.
c'est une vérité objective sur la forme du chiffre deux,
la forme abstraite.
Quand vous avez une chose en deux exemplaires -- deux yeux, deux oreilles, deux nez,
juste deux éléments --
ils participent tous à la forme du chiffre deux.
Ils participent aux vérités intrinsèques du chiffre deux.
Il y a du chiffre deux en chacun d'eux.
Par conséquent, ça ne dépend pas de l'opinion.
Et si, Platon se disait,
l'étique était comme les maths ?
Et s'il y avait une forme pure de justice ?
Et s'il y avait des vérités sur la justice,
et que vous pouviez simplement regarder le monde
et voir les choses qui y participent,
qui prennent part à cette forme de justice ?
Vous sauriez alors ce qui est vraiment juste et ce qui ne l'est pas.
Ça ne dépendrait pas
d'un simple jugement ou d'un simple aspect.
C'est une vision stupéfiante.
Je veux dire, pensez-y. C'est magnifique. C'est ambitieux.
C'est aussi ambitieux que nous.
Nous voulons résoudre les problèmes d'éthique.
Nous voulons des vérités objectives.
Si vous pensez de cette façon,
vous avez un système moral platonicien.
Si vous ne pensez pas de cette façon,
eh bien, vous n'êtes pas seul dans l'histoire de la philosophie occidentale,
parce que cette jolie idée -- vous savez, les gens l'ont critiquée.
Aristote, en particulier, n'a pas apprécié.
Il pensait que c'était infaisable en pratique.
Aristote disait : « Nous ne devrions chercher qu'autant d'exactitude dans un sujet
que celui-ci nous le permet. »
Aristote pensait que l'éthique n'était pas vraiment comme les maths.
Il pensait que l'éthique consistait à prendre des décision ici et maintenant
en utilisant notre meilleur jugement
pour trouver le droit chemin.
Si vous pensez cela, Platon n'est pas votre homme.
Mais n'abandonnez pas.
Peut-être y a-t-il un autre moyen
pour utiliser les nombres comme base de notre système moral.
Que diriez-vous de ceci :
et si dans n'importe quelle situation, vous pouviez simplement calculer,
examiner les possibilités,
évaluer laquelle est la meilleure et savoir quoi faire ?
Cela vous dit quelque chose ?
C'est un système moral utilitariste.
John Stuart Mill en était un grand partisan --
un type bien par ailleurs --
et il n'est mort que depuis 200 ans.
Donc les fondements de l'utilitarisme --
je suis sûr que vous les connaissez.
Les trois personnes qui ont voté pour Mill tout à l'heure savent ce que c'est.
Mais voilà comment ça fonctionne.
Et si la morale, si ce qui rend quelque chose moral,
n'était qu'un calcul de plaisir maximum
et de douleur minimum ?
C'est intrinsèque au fait.
Ça n'a pas de rapport avec sa forme abstraite.
C'est juste fonction des conséquences.
Vous regardez simplement les conséquences,
et vous voyez si, globalement, c'est pour le meilleur ou pour le pire.
Ce serait simple. Nous saurions ensuite quoi faire.
Prenons un exemple.
Imaginez que je vienne
et je dise : « Je vais vous prendre votre téléphone. »
Pas parce qu'il a sonné tout à l'heure,
mais parce que j'ai fait un petit calcul.
Je pensais que ce type avait l'air suspect.
Et s'il était en train d'envoyer des messages à la planque de Ben Laden --
ou de n'importe qui ayant pris la relève de Ben Laden --
c'est en fait un terroriste, une cellule dormante.
Je vais m'en rendre compte, et quand ce sera fait,
je vais éviter d'énormes dégâts qu'il pourrait causer.
L'intérêt est très grand d'éviter les dégâts,
comparé au moindre mal qu'il y aurait
si je le gêne en regardant dans son téléphone
pour découvrir qu'il ne faisait que jouer à Farmville --
c'est écrasé
par l'utilité d'examiner son téléphone.
Si vous pensez comme cela,
c'est un choix utilitariste.
Mais peut-être que vous ne pensez pas non plus comme ça.
Peut-être que vous vous dites : c'est son téléphone.
C'est mal de prendre son téléphone,
parce que c'est un individu
et il a des droits et il a une dignité,
et nous ne pouvons pas interférer avec ça.
Il est autonome.
Peut importe les calculs.
Ces choses sont intrinsèquement mauvaises --
comme mentir est mal,
de même que torturer des enfants innocents est mal.
Kant était vraiment bon sur ce sujet,
et il le disait un peu mieux que je vais le dire.
Il disait que nous devrions utiliser notre raison
pour décider des règles selon lesquelles nous devrions orienter notre conduite.
Il est ensuite de notre devoir de suivre ces règles.
Ça n'a rien à voir avec des calculs.
Arrêtons-nous.
Nous sommes au cœur de cet enchevêtrement philosophique.
Et le débat perdure depuis des milliers d'années,
parce que ce sont des questions difficiles,
et je n'ai que 15 minutes.
Alors allons droit au but.
Comment devrions-nous prendre nos décisions ?
Selon Platon, en accord avec Aristote, ou bien Kant, ou Mill ?
Que devrions-nous faire ? Quelle est la réponse ?
Quelle est la formule que nous pouvons utiliser dans n'importe quelle situation
pour déterminer ce que nous devrions faire ?
Si nous devrions utiliser les données de ce type ou pas ?
Quelle est la formule ?
Il n'y a pas de formule.
Il n'y a pas de réponse simple.
L'éthique, c'est difficile.
L'éthique exige une réflexion.
C'est inconfortable.
Je sais ; j'ai passé une grande partie de ma carrière
dans l'intelligence artificielle,
à essayer de construire des machines qui puissent réfléchir là-dessus pour nous,
qui puissent nous donner des réponses.
Mais elles ne le peuvent pas.
Vous ne pouvez pas simplement prendre la pensée humaine
et la mettre dans une machine.
Nous devons le faire par nous-mêmes.
Heureusement, nous ne sommes pas des machines, et nous pouvons le faire.
Nous pouvons non seulement penser,
mais nous le devons.
Hannah Arendt disait :
« La triste vérité
est que la plupart du mal fait en ce monde
n'est pas fait par des gens
qui ont choisi de faire le mal.
Il surgit de l'inexistence d'une réflexion. »
C'est ce qu'elle appelait « la banalité du mal. »
La réponse à cela
est que nous réclamons l'exercice de pensée
à toute personne sensée.
Faisons-donc cela. Pensons.
En fait, commençons dès maintenant.
Tout le monde dans la salle :
pensez à la dernière fois que vous avez dû prendre une décision
où vous étiez préoccupés de faire ce qui est juste,
où vous vous êtes demandés : « Que devrais-je faire ? »
Pensez à cela.
Réfléchissez maintenant à cela
et demandez-vous : « Comment ais-je pris cette décision ?
Qu'est-ce que j'ai fait ? Est-ce que j'ai suivi mon instinct ?
Est-ce que j'ai fait procéder à un vote ? Ou est-ce que j'ai fait appel au service juridique ? »
Ou bien nous avons d'autres choix maintenant.
« Est-ce que j'ai estimé ce qui procurerait le plus de plaisir,
comme Mill l'aurait fait ?
Ou comme Kant, ai-je utilisé ma raison pour décider de ce qui était intrinsèquement juste ?
Pensez-y. Vraiment. C'est important.
C'est si important
que nous allons passer 30 précieuses secondes de mon intervention à TED
à ne rien faire d'autre que d'y penser.
Vous êtes prêts ? Allez-y.
Arrêtez. Bon travail.
Ce que vous venez de faire,
c'est le premier pas vers la prise de responsabilité
concernant ce que nous devrions faire avec tout ce pouvoir.
La prochaine étape : essayez ceci.
Allez trouver un ami et expliquez-lui
comment vous avez pris cette décision.
Pas tout de suite. Attendez que j'ai terminé de parler.
Faites-le au déjeuner.
N'allez pas simplement trouver un autre ami technologue ;
trouvez quelqu'un de différent.
Trouvez un artiste ou un écrivain --
ou, Dieu vous en préserve, trouvez un philosophe et parlez leur.
En fait, trouvez quelqu'un dans les sciences humaines.
Pourquoi ? Parce qu'ils pensent aux problèmes
d'une manière différente à nous les technologues.
Il y a juste quelques jours, de l'autre côté de la rue ici,
il y avait un rassemblement de centaines de personnes.
C'était des technologues et des humanistes
à la grande BiblioTech Conférence.
Ils étaient rassemblés
parce que les technologues voulaient apprendre
ce que cela faisait de penser du point de vue des sciences sociales.
Vous avez quelqu'un de chez Google
qui parle à quelqu'un qui fait de la littérature comparée.
Vous vous demandez quel est l'intérêt du théâtre français du 17ème siècle --
quel est le lien avec le capital-risque ?
Eh bien, c'est intéressant. C'est une manière de penser différente.
Quand vous pensez de cette façon,
vous devenez plus sensible aux considérations humaines,
ce qui est crucial pour prendre des décisions éthiques.
Imaginez maintenant
que vous avez trouvé votre ami musicien.
Vous lui racontez ce dont on parle,
sur notre révolution des données et tout ça --
vous fredonnez peut-être quelques notes de notre thème musical.
♫ Dum ta da da dum dum ta da da dum ♫
Votre ami musicien va vous interrompre et vous dire :
« Tu sais, le thème musical
pour ta révolution des données,
c'est un opéra, c'est Wagner.
C'est basé sur une légende nordique.
Ce sont des dieux et des créatures mythologiques
qui se battent pour des bijoux magiques. »
C'est intéressant.
C'est aussi un magnifique opéra.
Nous sommes émus par cet opéra.
Nous sommes émus parce que c'est sur la bataille
entre le bien et le mal,
le juste et l'injuste.
Et nous nous préoccupons du juste et de l'injuste.
Nous nous soucions de ce qui se passe dans cet opéra.
Nous nous soucions de ce qui se passe dans "Apocalypse Now".
Et nous nous préoccupons certainement
de ce qui se passe avec nos technologies.
Nous avons tant de pouvoir aujourd'hui,
ça ne dépend que de nous de savoir ce qu'on en fait.
C'est la bonne nouvelle.
Nous sommes ceux qui écrivent cet opéra.
C'est notre film.
Nous décidons ce qui va arriver avec cette technologie.
Nous déterminons comment tout cela va finir.
Merci.
(Applaudissements)
